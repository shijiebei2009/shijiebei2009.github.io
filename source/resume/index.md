title: "Resume"
date: 2015-04-09 20:12:45

---
## 联系方式

- 手机：18302118258
- Email：wangx89@126.com
- 微信号：wangxu_89

---

## 个人信息
 - 王旭/男/1989
 - 本科/东南大学成贤学院（计算机工程系2009/09～2013/06）
 - 硕士研究生/上海大学（计算机工程与科学学院2013/09～2016/04）
 - 工作年限：暂时不找工作，勿扰
 - 技术博客：[http://blog.csdn.net/shijiebei2009](http://blog.csdn.net/shijiebei2009)
 - Github：[https://github.com/shijiebei2009](https://github.com/shijiebei2009)
 - 个人站点代码馆：[http://codepub.cn](http://codepub.cn)
 - 籍贯：江苏省徐州市睢宁县
 - 户口：上海市
 - 期望职位：① Hadoop/大数据工程师 ② Java工程师 ③ Python工程师
 - 期望薪资：面谈
 - 期望城市：上海、杭州、南京

---
## 工作/项目经历
### [阅文集团](http://join.yuewen.com/)(2015/12 ~ Now)
#### 技术部-内容中心
##### 书籍入库统计，分全量增量，统计不同站点不同分类不同作家分组的书籍数量（按日、周、月、年分别统计）
##### [基于Redis的Lucene索引存储系统](https://github.com/shijiebei2009/RedisDirectory)
##### 武侠世界海外站点的小说爬虫项目，使用Jsoup抓取内容，并完成数据清洗存储，分全量增量
##### 作家创作天数统计，统计每个作家从注册到现在的创作天数，有章节更新天记为一有效天，分全量增量



### [大众点评网](http://www.dianping.com/)(2015/6/24 ~ 2015/10/8)
#### POI（Point of Interest）与基础内容
##### 菜单匹配服务
将用户推荐菜与系统中商户菜单进行匹配，前期使用Python脚本编写算法部分，接收推荐菜与商户菜单组成的CSV输入文件，输出CSV匹配结果，用shell脚本从Hive数据库中拉取数据，使用Linux定时任务每天每一小时执行一次。

**存在的问题**：每次均为全量更新，当系统菜单数据量很大时每次拉取数据都会给Hive数据库很大压力，所以后期用Java重构为增量更新。

**增量更新解决方案**：
① 由DBA方负责出一个拉取系统菜单接口，接收一个开始时间，会检索在开始时间之后更新的系统菜单表
② 根据拉取到的系统菜单去增量拉取推荐菜，两张表通过公共的shopId关联
② 线程每两小时调用一次接口，每次调用传递一个参数，该参数是上一次调用该接口的时间，将获取的数据写入推荐菜与系统菜单关系表，初始化为未匹配
③ 算法开始工作，根据同一个shopId，查询到该商户对应的推荐菜与系统菜单，挖掘菜品之间的关系，工作结束后，更新推荐菜与系统菜单关系表，关系有：精确匹配，格式化后匹配，近似匹配
④ 对外暴露服务，供有需求方进行查询，获取到推荐菜与系统菜单之间的关系

**实现的效果**：
只有服务第一次启动开始工作的时候，会进行全量更新，之后每次工作都是增量更新基本对数据库无影响，并可以对外提供稳定的服务。

**压测结果**：
① QPS（**Q**uery **P**er **S**econd）：峰值75左右
② 响应时间**99线** < **100ms**（99%的请求响应时间在100ms以下）
③ 目前的系统菜单数据量：**3亿**，后期还会增加

**挖掘关系部分算法**
* 精确匹配（文本完全一致）
* 基于词典精确匹配
 - 分析菜单表，手工构建量词词典，对系统菜单进行格式化
 - 由运营方提供系统菜单后缀词典（该后缀为无意义的通用部分），对系统菜单进行格式化
* 近似模糊匹配
 - 计算编辑距离
 - 计算公共子序列(有序，非连续)
 - 计算公共子串(有序，且连续)
 - 根据评分公式计算相似度并辅之以动态变化的阈值，一般地短的字符串设置较高的阈值，长的字符串可稍微放宽阈值

##### 商户判重服务的客户端
封装了商户判重的Pigeon2服务（分布式服务通信框架）并对外提供两个接口，接收包含商户信息的CSV输入文件，该文件有两种格式，其一两两商户以成对形式出现，通过GroupId进行标识，其中之一为其他商户信息称为基准POI，另一个商户为点评商户，调用两两匹配接口，判断该对商户之间的关系。另一接口为接收全部是基准POI信息的商户，从点评已有商户中查询与之匹配的商户。

**实现的效果**
运营人员会不定期对判重服务的结果进行人工抽检，而该客户端只需要接收包含商户信息的输入文件，会将判重的结果以CSV或Excel文件的形式返回，供运营人员分析结果。

##### 其他项目
>判重服务的内部分档与业务分档关系配置平台，属于Web平台开发，使用Bootstrap进行页面布局，用JS+Ajax实现同一页面的CRUD操作。
>使用Selenium模拟用户登录支付宝账户，并自动根据交易号或者商户订单号查询交易对方信息。
>点评Shop库的全量自去重结果处理，从2.7K万Shop数据中，发现427万疑似重复以及不确定是否重复商户，目前已处理重复档及疑似重复档商户70万，剩余350万不确定关系商户

##### 商户判重服务
由爬虫组负责从其他网站上抓取商户信息，与点评已有的两千七百万家商户信息进行比较。如果是与点评已有商户不重复的需要新增上线，与点评已有商户不确定关系的需要人工介入，与点评已有商户重复或可能重复的需要将关系入库。

在商户比较中，利用到的信息字段如下
* 商户名（别名、商户名、结构化商户名、分店名）
* 地址（地址、结构化地址、交叉路、经纬度）
* 富信息（电话、类别【频道（例亲子、结婚、美食、酒店）、类目信息】）

在商户比较中，使用到的主要特征策略如下
* 商户名
   - 模糊比较（编辑距离、杰卡德相似系数、包含关系【头包含、尾包含、连续包含、非连续包含】）
   - 结构化比较（主干比较、分支比较、总体结构比较）
* 地址
     - 结构化比较（商区、区县、乡镇、街道、楼层、弄、门牌）
     - 模糊比较
     - 距离比较（基于经纬度）

### 张江徐汇科企联研资源共享平台(2014/8 ~ 2014/11)
#### 文档分析模块
在该项目中主要负责：导入word/pdf格式文档、文档基本统计信息提取、文档格式化信息抽取、文档摘要抽取、站内文档搜索引擎接口（基于Lucene）、根据关键词词频的文档匹配。在下面讲义部分会提供PPT演示地址。

### 北京科蓝软件系统有限公司(上海分公司)(2013/7 ~ 2013/9)
#### 江苏农村信用合作社网银开发
使用科蓝公司内部框架及系统进行江苏农信网上银行的开发工作，由于工作时间较短，仅完成了一个发版申请；发版项目名称：支付签约管理；发版事由：支付签约管理统计开销户数。使用公司内部研发框架，在入职前期对我们做了一些银行业务方面的培训，并花了一定时间用来熟悉框架、使用、以及配置上等。

---
## 开源项目和作品
### 开源项目
 - [Automatic Annotation](https://github.com/shijiebei2009/CEC-Automatic-Annotation) : 该项目主要是基于CEC语料库的分析，使用序列模式挖掘算法挖掘事件要素识别规则，包括词性规则、命名实体规则、句法分析规则等，将互联网上获取的突发事件类生语料经过哈工大LTP分析，获取分词、命名实体识别、句法分析、语义角色标注、依存分析等一系列结果，基于此结果做进一步的处理，然后完成对突发事件类生语料的自动标注工作
 - [在线观看](http://v.youku.com/v_show/id_XOTEzNDcyOTQ0.html)
 - [视频下载](http://pan.baidu.com/s/1nt62S7R) :针对自动标注（Automatic annotation） 项目进行视频介绍与说明

### 演讲和讲义
  - 2014高智公司项目进展研讨会：[关键技术介绍](http://pan.baidu.com/s/1eQgsPeM)
  - 2014高智公司项目进展研讨会：[版本更新](http://pan.baidu.com/s/1c02H4D6)

## 技能清单

- Web开发：Java/Python
- Web框架：Struts2/Hibernate/Spring/MyBatis
- 前端框架：Bootstrap/HTML5/JQuery
- 数据库相关：MySQL/MongoDB/Oracle/SQLServer
- 版本管理、文档和自动化部署工具：CVS/Svn/Git
- 项目构建：Ant/Maven(Nexus)
- 单元测试：JUnit
- 开源框架：Lucene、Heritrix
- 云和开放平台：新浪SAE
- 业余玩耍：Scala/PHP/Android/CeontOS/Hadoop
- NLP相关：IKanalyzer/Paoding/FudanNLP/LTP/Stanford coreNLP/RDF/OWL/Jena
- 开发工具：Eclipse/IntelliJ IDEA

---
## 致谢
感谢您花时间阅读我的简历，期待能有机会和您共事。